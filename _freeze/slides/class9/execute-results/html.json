{
  "hash": "9229852ca33cee85721371dbcafa3b3d",
  "result": {
    "markdown": "---\ntitle: \"A Quick Primer on Diff-in-Diff\"\nauthor: \"Ian McCarthy, Emory University and NBER\"\ninstitute: \"Emory University, 2024\"\nformat: \n  revealjs:\n    theme: [simple, quarto-styles.scss]\n    preview-links: auto\n#    chalkboard:\n#      boardmarker-width: 5\n    slide-number: true\n    width: 1600\n    height: 900\n    embed-resources: true\nfrom: markdown+emoji\nexecute: \n  echo: true\nbibliography: ../files/bib/references.bib  \n---\n\n\n\n\n## Outline\n\n1. Panel Data and Fixed Effects\n2. Difference-in-Differences Yesterday\n3. Difference-in-Differences Today\n4. Brief Notes on Empirical Exercise\n\n\n# Panel Data and Fixed Effects\n\n\n---\n\n## Basics of panel data\n\n- Repeated observations of the same units over time (balanced vs unbalanced)\n- Identification due to variation **within unit**\n\n::: {.fragment}\n**Notation**\n\n- Unit $i=1,...,N$ over several periods $t=1,...,T$, which we denote $y_{it}$\n- Treatment status $D_{it}$\n- Regression model, <br>\n$y_{it} = \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\epsilon_{it}$ for $t=1,...,T$ and $i=1,...,N$\n:::\n\n---\n\n## Benefits of Panel Data\n\n- *May* overcome certain forms of omitted variable bias\n- Allows for unobserved but time-invariant factor, $\\gamma_{i}$, that affects both treatment and outcomes\n\n::: {.fragment}\n**Still assumes**\n\n- No time-varying confounders \n- Past outcomes do not directly affect current outcomes\n- Past outcomes do not affect treatment (reverse causality)\n:::\n\n---\n\n## Some textbook settings\n\n- Unobserved \"ability\" when studying schooling and wages\n- Unobserved \"quality\" when studying physicians or hospitals\n\n---\n\n## Fixed effects and regression\n\n$y_{it} = \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\epsilon_{it}$ for $t=1,...,T$ and $i=1,...,N$\n\n::: {.fragment}\n\n- Allows correlation between $\\gamma_{i}$ and $D_{it}$\n- Physically estimate $\\gamma_{i}$ in some cases via set of dummy variables\n- More generally, \"remove\" $\\gamma_{i}$ via:\n  - \"within\" estimator\n  - first-difference estimator\n:::\n\n---\n\n## Within Estimator\n\n$y_{it} = \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\epsilon_{it}$ for $t=1,...,T$ and $i=1,...,N$\n\n::: {.fragment}\n\n- Most common approach (default in most statistical software)\n- Equivalent to demeaned model:\n$$y_{it} - \\bar{y}_{i} = \\delta (D_{it} - \\bar{D}_{i}) + (\\gamma_{i} - \\bar{\\gamma}_{i}) + (\\gamma_{t} - \\bar{\\gamma}_{t}) + (\\epsilon_{it} - \\bar{\\epsilon}_{i})$$\n\n- $\\gamma_{i} - \\bar{\\gamma}_{i} = 0$ since $\\gamma_{i}$ is time-invariant\n- Requires *strict exogeneity* assumption (error is uncorrelated with $D_{it}$ for all time periods)\n:::\n\n---\n\n## First-difference\n\n$y_{it} = \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\epsilon_{it}$ for $t=1,...,T$ and $i=1,...,N$\n\n::: {.fragment}\n\n- Instead of subtracting the mean, subtract the prior period values\n$$y_{it} - y_{i,t-1} = \\delta(D_{it} - D_{i,t-1}) + (\\gamma_{i} - \\gamma_{i}) + (\\gamma_{t} - \\gamma_{t-1}) + (\\epsilon_{it} - \\epsilon_{i,t-1})$$\n\n- Requires exogeneity of $\\epsilon_{it}$ and $D_{it}$ only for time $t$ and $t-1$ (weaker assumption than within estimator)\n- Sometimes useful to estimate both FE and FD just as a check\n:::\n\n---\n\n## Keep in mind...\n\n- Discussion only applies to linear case or very specific nonlinear models\n- Fixed effects at lower \"levels\" accommodate fixed effects at higher levels (e.g., FEs for hospital combine to form FEs for zip code, etc.)\n- Fixed effects can't solve reverse causality\n- Fixed effects don't address unobserved, time-varying confounders\n- Can't estimate effects on time-invariant variables\n- May \"absorb\" a lot of the variation for variables that don't change much over time\n\n\n---\n\n## Within Estimator (Default) in practice\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n**Stata**\n\n::: {.cell}\n\n```{.stata .cell-code}\nssc install causaldata\ncausaldata gapminder.dta, use clear download\ngen lgdp_pc=log(gdppercap)\ntsset country year\nxtreg lifeExp lgdp_pc, fe\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**R**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fixest)\nlibrary(causaldata)\nreg.dat <- causaldata::gapminder %>%\n  mutate(lgdp_pc=log(gdpPercap))\nfeols(lifeExp~lgdp_pc | country, data=reg.dat)\n```\n:::\n\n\n:::\n\n::::\n\n\n\n\n\n---\n\n## Within Estimator (Default) in practice\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nlibrary(fixest)\nlibrary(modelsummary)\nlibrary(causaldata)\nreg.dat <- causaldata::gapminder %>%\n  mutate(lgdp_pc=log(gdpPercap))\nm1 <- feols(lifeExp ~ lgdp_pc | country, data=reg.dat)\nmodelsummary(list(\"Default FE\"=m1), \n             shape=term + statistic ~ model, \n             gof_map=NA, \n             coef_rename=c(\"lgdp_pc\"=\"Log GDP per Capita\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Default FE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Log GDP per Capita </td>\n   <td style=\"text-align:center;\"> 9.769 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.702) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n---\n\n## Within Estimator (Manually Demean) in practice\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n**Stata**\n\n::: {.cell}\n\n```{.stata .cell-code}\ncausaldata gapminder.dta, use clear download\ngen lgdp_pc=log(gdppercap)\nforeach x of varlist lifeExp lgdp_pc {\n  egen mean_`x'=mean(`x')\n  egen demean_`x'=`x'-mean_`x'\n}\nreg demean_lifeExp demean_lgdp_pc\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**R**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(causaldata)\nreg.dat <- causaldata::gapminder %>%\n  mutate(lgdp_pc=log(gdpPercap)) %>%\n  group_by(country) %>%\n  mutate(demean_lifeexp=lifeExp - mean(lifeExp, na.rm=TRUE),\n         demean_gdp=lgdp_pc - mean(lgdp_pc, na.rm=TRUE))\nlm(demean_lifeexp~ 0 + demean_gdp, data=reg.dat)\n```\n:::\n\n:::\n\n::::\n\n---\n\n## Within Estimator (Manually Demean) in practice\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nlibrary(lmtest)\nreg.dat <- causaldata::gapminder %>%\n  group_by(country) %>%\n  mutate(lgdp_pc=log(gdpPercap),\n         lgdp_pc=lgdp_pc - mean(lgdp_pc, na.rm=TRUE),\n         lifeExp=lifeExp - mean(lifeExp, na.rm=TRUE))\n\nm2 <- lm(lifeExp~ 0 + lgdp_pc , data=reg.dat)\nmodelsummary(list(\"Default FE\"=m1, \"Manual FE\"=m2), \n             shape=term + statistic ~ model, \n             gof_map=NA, \n             coef_rename=c(\"lgdp_pc\"=\"Log GDP per Capita\"),\n             vcov = ~country)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Default FE </th>\n   <th style=\"text-align:center;\"> Manual FE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Log GDP per Capita </td>\n   <td style=\"text-align:center;\"> 9.769 </td>\n   <td style=\"text-align:center;\"> 9.769 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.702) </td>\n   <td style=\"text-align:center;\"> (0.701) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Note:** `feols` defaults to clustering at level of FE, `lm` requires our input\n\n---\n\n## First differencing (default) in practice\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n**Stata**\n\n::: {.cell}\n\n```{.stata .cell-code}\ncausaldata gapminder.dta, use clear download\ngen lgdp_pc=log(gdppercap)\nreg d.lifeExp d.lgdp_pc, noconstant\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**R**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plm)\nreg.dat <- causaldata::gapminder %>%\n  mutate(lgdp_pc=log(gdpPercap))\n\nplm(lifeExp ~ 0 + lgdp_pc, model=\"fd\", individual=\"country\", index=c(\"country\",\"year\"), data=reg.dat)\n```\n:::\n\n:::\n\n::::\n\n\n---\n\n## First differencing (manual) in practice\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nlibrary(plm)\nreg.dat <- causaldata::gapminder %>%\n  mutate(lgdp_pc=log(gdpPercap))\n\nm3 <- plm(lifeExp ~ 0 + lgdp_pc, model=\"fd\", index=c(\"country\",\"year\"), data=reg.dat)\n\nmodelsummary(list(\"Default FE\"=m1, \"Manual FE\"=m2, \"Default FD\"=m3), \n             shape=term + statistic ~ model, \n             gof_map=NA, \n             coef_rename=c(\"lgdp_pc\"=\"Log GDP per Capita\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Default FE </th>\n   <th style=\"text-align:center;\"> Manual FE </th>\n   <th style=\"text-align:center;\"> Default FD </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Log GDP per Capita </td>\n   <td style=\"text-align:center;\"> 9.769 </td>\n   <td style=\"text-align:center;\"> 9.769 </td>\n   <td style=\"text-align:center;\"> 5.290 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.702) </td>\n   <td style=\"text-align:center;\"> (0.284) </td>\n   <td style=\"text-align:center;\"> (0.291) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n---\n\n## First differencing (manual) in practice\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n**Stata**\n\n::: {.cell}\n\n```{.stata .cell-code}\ncausaldata gapminder.dta, use clear download\ngen lgdp_pc=log(gdppercap)\nreg d.lifeExp d.lgdp_pc, noconstant\n```\n:::\n\n:::\n\n\n::: {.column width=\"50%\"}\n**R**\n\n::: {.cell}\n\n```{.r .cell-code}\nreg.dat <- causaldata::gapminder %>%\n  mutate(lgdp_pc=log(gdpPercap)) %>%  \n  group_by(country) %>%\n  arrange(country, year) %>%\n  mutate(fd_lifeexp=lifeExp - lag(lifeExp),\n         lgdp_pc=lgdp_pc - lag(lgdp_pc)) %>%\n  na.omit()\n\nlm(fd_lifeexp~ 0 + lgdp_pc , data=reg.dat)\n```\n:::\n\n:::\n\n::::\n\n---\n\n## First differencing (manual) in practice\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nreg.dat <- causaldata::gapminder %>%\n  mutate(lgdp_pc=log(gdpPercap)) %>%  \n  group_by(country) %>%\n  arrange(country, year) %>%  \n  mutate(fd_lifeexp=lifeExp - dplyr::lag(lifeExp),\n         lgdp_pc=lgdp_pc - dplyr::lag(lgdp_pc)) %>%\n  na.omit()\n\nm4 <- lm(fd_lifeexp~ 0 + lgdp_pc , data=reg.dat)\nmodelsummary(list(\"Default FE\"=m1, \"Manual FE\"=m2, \"Default FD\"=m3, \"Manual FD\"=m4), \n             shape=term + statistic ~ model, \n             gof_map=NA, \n             coef_rename=c(\"lgdp_pc\"=\"Log GDP per Capita\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Default FE </th>\n   <th style=\"text-align:center;\"> Manual FE </th>\n   <th style=\"text-align:center;\"> Default FD </th>\n   <th style=\"text-align:center;\"> Manual FD </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Log GDP per Capita </td>\n   <td style=\"text-align:center;\"> 9.769 </td>\n   <td style=\"text-align:center;\"> 9.769 </td>\n   <td style=\"text-align:center;\"> 5.290 </td>\n   <td style=\"text-align:center;\"> 5.290 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.702) </td>\n   <td style=\"text-align:center;\"> (0.284) </td>\n   <td style=\"text-align:center;\"> (0.291) </td>\n   <td style=\"text-align:center;\"> (0.291) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n---\n\n## FE and FD with same time period\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nreg.dat2 <- causaldata::gapminder %>%\n  mutate(lgdp_pc=log(gdpPercap)) %>%\n  inner_join(reg.dat %>% select(country, year), by=c(\"country\",\"year\"))\nm5 <- feols(lifeExp ~ lgdp_pc | country, data=reg.dat2)\nmodelsummary(list(\"Default FE\"=m5, \"Default FD\"=m3, \"Manual FD\"=m4), \n             shape=term + statistic ~ model, \n             gof_map=NA, \n             coef_rename=c(\"lgdp_pc\"=\"Log GDP per Capita\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Default FE </th>\n   <th style=\"text-align:center;\"> Default FD </th>\n   <th style=\"text-align:center;\"> Manual FD </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Log GDP per Capita </td>\n   <td style=\"text-align:center;\"> 8.929 </td>\n   <td style=\"text-align:center;\"> 5.290 </td>\n   <td style=\"text-align:center;\"> 5.290 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.741) </td>\n   <td style=\"text-align:center;\"> (0.291) </td>\n   <td style=\"text-align:center;\"> (0.291) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nDon't want to read too much into this, but...\n\n- Likely strong serial correlation in this case (almost certainly)\n- Mispecified model\n\n# Difference-in-Differences Yesterday\n\n\n---\n\n## Basic 2x2 Setup\n\nWant to estimate $ATT = E[Y_{1}(1)- Y_{0}(1) | D=1]$\n\n|           | Pre-Period         | Post-Period       |\n|-----------|:-------------------|:------------------|\n| Treatment | $E(Y_{0}(0)|D=1)$  | $E(Y_{1}(1)|D=1)$ |\n| Control   | $E(Y_{0}(0)|D=0)$  | $E(Y_{0}(1)|D=0)$ |\n\n::: {.fragment}\n<br>\n\n**Problem:** We don't see $E[Y_{0}(1)|D=1]$\n:::\n\n---\n\n## Basic 2x2 Setup\n\nWant to estimate $ATT = E[Y_{1}(1)- Y_{0}(1) | D=1]$\n\n|           | Pre-Period         | Post-Period       |\n|-----------|:-------------------|:------------------|\n| Treatment | $E(Y_{0}(0)|D=1)$  | $E(Y_{1}(1)|D=1)$ |\n| Control   | $E(Y_{0}(0)|D=0)$  | $E(Y_{0}(1)|D=0)$ |\n\n::: {.fragment}\n<br>\n\n**Strategy 1:** Estimate $E[Y_{0}(1)|D=1]$ using $E[Y_{0}(0)|D=1]$ (before treatment outcome used to estimate post-treatment)\n:::\n\n\n\n---\n\n## Basic 2x2 Setup\n\nWant to estimate $ATT = E[Y_{1}(1)- Y_{0}(1) | D=1]$\n\n|           | Pre-Period         | Post-Period       |\n|-----------|:-------------------|:------------------|\n| Treatment | $E(Y_{0}(0)|D=1)$  | $E(Y_{1}(1)|D=1)$ |\n| Control   | $E(Y_{0}(0)|D=0)$  | $E(Y_{0}(1)|D=0)$ |\n\n::: {.fragment}\n<br>\n\n**Strategy 2:** Estimate $E[Y_{0}(1)|D=1]$ using $E[Y_{0}(1)|D=0]$ (control group used to predict outcome for treatment)\n:::\n\n\n\n---\n\n## Basic 2x2 Setup\n\nWant to estimate $ATT = E[Y_{1}(1)- Y_{0}(1) | D=1]$\n\n|           | Pre-Period         | Post-Period       |\n|-----------|:-------------------|:------------------|\n| Treatment | $E(Y_{0}(0)|D=1)$  | $E(Y_{1}(1)|D=1)$ |\n| Control   | $E(Y_{0}(0)|D=0)$  | $E(Y_{0}(1)|D=0)$ |\n\n::: {.fragment}\n<br>\n\n**Strategy 3: DD**\n\n<br>\n\nEstimate $E[Y_{1}(1)|D=1] - E[Y_{0}(1)|D=1]$ using $E[Y_{0}(1)|D=0] - E[Y_{0}(0)|D=0]$ (pre-post difference in control group used to predict difference for treatment group)\n:::\n\n\n---\n\n## Graphically\n\n![Basic DD Graph](/files/figures/standard-dd.png){}\n\n\n---\n\n## Animations\n\n![Basic DD Graph, Animated](/files/figures/dd_animate.gif){}\n\n---\n\n## ATE Estimates with DD\n\nKey identifying assumption is that of *parallel trends*\n\n$$E[Y_{0}(1) - Y_{0}(0)|D=1] = E[Y_{0}(1) - Y_{0}(0)|D=0]$$\n\n\n---\n\n## Estimation: Sample Means\n\n$$\\begin{align}\nE[Y_{1}(1) - Y_{0}(1)|D=1] &=& \\left( E[Y(1)|D=1] - E[Y(1)|D=0] \\right) \\\\\n & & - \\left( E[Y(0)|D=1] - E[Y(0)|D=0]\\right)\n\\end{align}$$\n\n\n---\n\n## Estimation: Regression\n\n$$y_{it} = \\alpha + \\beta D_{i} + \\lambda \\times Post_{t} + \\delta \\times D_{i} \\times Post_{t} + \\varepsilon_{it}$$\n\n::: {.fragment}\n\n|           | Pre               | Post                                 | Post - Pre           |\n|-----------|:------------------|:-------------------------------------|:---------------------|\n| Treatment | $\\alpha + \\beta$  | $\\alpha + \\beta + \\lambda + \\delta$ | $\\lambda + \\delta$  |\n| Control   | $\\alpha$          | $\\alpha + \\lambda$                  | $\\lambda$            |\n| Diff      | $\\beta$           | $\\beta + \\delta$                    | $\\delta$             |\n\n:::\n\n\n---\n\n## Simulated data\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 5000\ndd.dat <- tibble(\n  d = (runif(N, 0, 1)>0.5),\n  time_pre = \"pre\",\n  time_post = \"post\"\n)\n\ndd.dat <- pivot_longer(dd.dat, c(\"time_pre\",\"time_post\"), values_to=\"time\") %>%\n  select(d, time) %>%\n  mutate(t=(time==\"post\"),\n         y.out=1.5+3*d + 1.5*t + 6*d*t + rnorm(N*2,0,1))\n```\n:::\n\n\n---\n\n## Mean differences\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\ndd.means <- dd.dat %>% group_by(d, t) %>% summarize(mean_y = mean(y.out)) %>% mutate(d=ifelse(d==TRUE, \"Treated\", \"Control\"), t=ifelse(t==TRUE, \"Post\", \"Pre\"))\n\nknitr::kable(dd.means, col.names=c(\"Treated\",\"Period\",\"Mean\"), format=\"html\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Treated </th>\n   <th style=\"text-align:left;\"> Period </th>\n   <th style=\"text-align:right;\"> Mean </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Control </td>\n   <td style=\"text-align:left;\"> Pre </td>\n   <td style=\"text-align:right;\"> 1.483339 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Control </td>\n   <td style=\"text-align:left;\"> Post </td>\n   <td style=\"text-align:right;\"> 2.998502 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Treated </td>\n   <td style=\"text-align:left;\"> Pre </td>\n   <td style=\"text-align:right;\"> 4.515737 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Treated </td>\n   <td style=\"text-align:left;\"> Post </td>\n   <td style=\"text-align:right;\"> 12.034735 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n---\n\n## Mean differences\n\nIn this example:\n\n- $E[Y(1)|D=1] - E[Y(1)|D=0]$ is 9.0362327\n- $E[Y(0)|D=1] - E[Y(0)|D=0]$ is 3.0323975\n\n::: {.fragment}\nSo the ATT is 6.0038352\n:::\n\n\n---\n\n## Regression estimator\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nlibrary(modelsummary)\ndd.est <- lm(y.out ~ d + t + d*t, data=dd.dat)\nmodelsummary(dd.est, gof_map=NA, coef_omit='Intercept')\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\">  (1) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> dTRUE </td>\n   <td style=\"text-align:center;\"> 3.032 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.028) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tTRUE </td>\n   <td style=\"text-align:center;\"> 1.515 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.028) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> dTRUE × tTRUE </td>\n   <td style=\"text-align:center;\"> 6.004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.040) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n---\n\n## Application\n\n- Try out some real data on Medicaid expansion following the ACA\n- Data is small part of DD empirical assignment\n- **Question:** Did Medicaid expansion reduce uninsurance?\n\n---\n\n## Step 1: Look at the data\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n**Stata**\n\n\n::: {.cell}\n\n```{.stata .cell-code}\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\nkeep if expand_year==\"2014\" | expand_year==\"NA\"\ndrop if expand_ever==\"NA\"\ncollapse (mean) perc_unins, by(year expand_ever)\ngraph twoway (connected perc_unins year if expand_ever==\"FALSE\", color(black) lpattern(solid)) ///\n  (connected perc_unins year if expand_ever==\"TRUE\", color(black) lpattern(dash)), ///\n  xline(2013.5) ///\n\tytitle(\"Fraction Uninsured\") xtitle(\"Year\") legend(off) text(0.15 2017 \"Non-expansion\", place(e)) text(0.08 2017 \"Expansion\", place(e))\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n**R**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)  \nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nins.plot.dat <- mcaid.data %>% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop) %>%\n  group_by(expand_ever, year) %>% summarize(mean=mean(perc_unins))\n\nins.plot <- ggplot(data=ins.plot.dat, aes(x=year,y=mean,group=expand_ever,linetype=expand_ever)) + \n  geom_line() + geom_point() + theme_bw() +\n  geom_vline(xintercept=2013.5, color=\"red\") +\n  geom_text(data = ins.plot.dat %>% filter(year == 2016), \n            aes(label = c(\"Non-expansion\",\"Expansion\"),\n                x = year + 1,\n                y = mean)) +\n  guides(linetype=\"none\") +\n  labs(\n    x=\"Year\",\n    y=\"Fraction Uninsured\",\n    title=\"Share of Uninsured over Time\"\n  )\n```\n:::\n\n:::\n\n::::\n\n---\n\n## Step 1: Look at the data\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](class9_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n\n---\n\n## Step 2: Estimate effects\n\nInterested in $\\delta$ from:\n\n$$y_{it} = \\alpha + \\beta \\times Post_{t} + \\lambda \\times Expand_{i} + \\delta \\times Post_{t} \\times Expand_{i} + \\varepsilon_{it}$$\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n**Stata**\n\n\n::: {.cell}\n\n```{.stata .cell-code}\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\nkeep if expand_year==\"2014\" | expand_year==\"NA\"\ndrop if expand_ever==\"NA\"\ngen post=(year>=2014)\ngen treat=(expand_ever==\"TRUE\")\ngen treat_post=(expand==\"TRUE\")\n\nreg perc_unins treat post treat_post\n\n**also try didregress\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**R**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(modelsummary)\nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat <- mcaid.data %>% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever)\n\ndd.ins.reg <- lm(perc_unins ~ post + expand_ever + post*expand_ever, data=reg.dat)\n```\n:::\n\n:::\n\n::::\n\n---\n\n## Step 2: Estimate effects\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nmodelsummary(list(\"DD (2014)\"=dd.ins.reg),\n             shape=term + statistic ~ model, \n             gof_map=NA,\n             coef_omit='Intercept',\n             vcov=~State\n         )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\">  DD (2014) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> postTRUE </td>\n   <td style=\"text-align:center;\"> −0.054 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.003) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> expand_everTRUE </td>\n   <td style=\"text-align:center;\"> −0.046 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.016) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> postTRUE × expand_everTRUE </td>\n   <td style=\"text-align:center;\"> −0.019 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.007) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n---\n\n## Final DD thoughts\n\n- Key identification assumption is **parallel trends**\n- Inference: Typically want to cluster at unit-level to allow for correlation over time within units, but problems with small numbers of treated or control groups:\n    - Conley-Taber CIs\n    - Wild cluster bootstrap\n    - Randomization inference\n- \"Extra\" things like propensity score weighting and doubly robust estimation\n\n\n---\n\n## DD and TWFE?\n\n- Just a shorthand for a common regression specification\n- Fixed effects for each unit and each time period, $\\gamma_{i}$ and $\\gamma_{t}$\n- More general than 2x2 DD but same result\n\n---\n\n## What is TWFE?\n\nWant to estimate $\\delta$:\n\n$$y_{it} = \\alpha + \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\varepsilon_{it},$$\n\nwhere $\\gamma_{i}$ and $\\gamma_{t}$ denote a set of unit $i$ and time period $t$ dummy variables (or fixed effects).\n\n---\n\n## TWFE in Practice\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n**2x2 DD**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(modelsummary)\nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat <- mcaid.data %>% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever)\nm.dd <- lm(perc_unins ~ post + expand_ever + treat, data=reg.dat)\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**TWFE**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fixest)\nm.twfe <- feols(perc_unins ~ treat | State + year, data=reg.dat)\n```\n:::\n\n:::\n\n::::\n\n---\n\n## TWFE in Practice\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nmsummary(list(\"DD\"=m.dd, \"TWFE\"=m.twfe),\n         shape=term + statistic ~ model, \n         gof_map=NA,\n         coef_omit='Intercept',\n         vcov=~State\n         )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> DD </th>\n   <th style=\"text-align:center;\"> TWFE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> postTRUE </td>\n   <td style=\"text-align:center;\"> −0.054 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.003) </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> expand_everTRUE </td>\n   <td style=\"text-align:center;\"> −0.046 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.016) </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> treat </td>\n   <td style=\"text-align:center;\"> −0.019 </td>\n   <td style=\"text-align:center;\"> −0.019 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.007) </td>\n   <td style=\"text-align:center;\"> (0.007) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n---\n\n## Event study\n\nEvent study is poorly named:\n\n- In finance, even study is just an *interrupted time series*\n- In econ and other areas, we usually have a treatment/control group *and* a break in time\n\n---\n\n## Why show an event study?\n\n- Allows for heterogeneous effects over time (maybe effects phase in over time or dissipate)\n- Visually very appealing\n- Offers easy evidence against or consistent with parallel trends assumption\n\n\n---\n\n## How to do an event study?\n\nEstimate something akin to...\n$$y_{it} = \\gamma_{i} + \\gamma_{t} + \\sum_{\\tau = -q}^{-2}\\delta_{\\tau} D_{i \\tau} + \\sum_{\\tau=0}^{m} \\delta_{\\tau}D_{i \\tau} + \\beta x_{it} + \\epsilon_{it},$$\n\nwhere $q$ captures the number of periods before the treatment occurs and $m$ captures periods after treatment occurs.\n\n---\n\n## How to do an event study?\n\n1. Create all treatment/year interactions\n2. Regressions with full set of interactions and group/year FEs\n3. Plot coefficients and standard errors\n\n\n---\n\n## Things to address\n\n1. \"Event time\" vs calendar time\n2. Define baseline period\n3. Choose number of pre-treatment and post-treatment coefficients\n\n\n---\n\n## Event time vs calendar time\n\nEssentially two \"flavors\" of event studies\n\n1. Common treatment timing\n2. Differential treatment timing\n\n---\n\n## Define baseline period\n\n- Must choose an \"excluded\" time period (as in all cases of group dummy variables)\n- Common choice is $t=-1$ (period just before treatment)\n- Easy to understand with calendar time\n- For event time...manually set time to $t=-1$ for all untreated units\n\n---\n\n## Number of pre-treatment and post-treatment periods\n\n- On event time, sometimes very few observations for large lead or lag values\n- Medicaid expansion example: Late adopting states have fewer post-treatment periods\n- Norm is to group final lead/lag periods together\n\n\n---\n\n## Commont treatment timing\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n**Stata**\n\n::: {.cell}\n\n```{.stata .cell-code}\nssc install reghdfe\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\nkeep if expand_year==\"2014\" | expand_year==\"NA\"\ndrop if expand_ever==\"NA\"\ngen post=(year>=2014)\ngen treat=(expand_ever==\"TRUE\")\ngen treat_post=(expand==\"TRUE\")\n\nreghdfe perc_unins treat##ib2013.year, absorb(state)\ngen coef = .\ngen se = .\nforvalues i = 2012(1)2018 {\n    replace coef = _b[1.treat#`i'.year] if year == `i'\n    replace se = _se[1.treat#`i'.year] if year == `i'\n}\n\n* Make confidence intervals\ngen ci_top = coef+1.96*se\ngen ci_bottom = coef - 1.96*se\n\n* Limit ourselves to one observation per year\nkeep year coef se ci_*\nduplicates drop\n\n* Create connected scatterplot of coefficients\n* with CIs included with rcap \n* and a line at 0 from function\ntwoway (sc coef year, connect(line)) (rcap ci_top ci_bottom year) ///\n    (function y = 0, range(2012 2018)), xtitle(\"Year\") ///\n    caption(\"Estimates and 95% CI from Event Study\")\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n**R**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(fixest)\nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat <- mcaid.data %>% \n  filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever)\n\nmod.twfe <- feols(perc_unins~i(year, expand_ever, ref=2013) | State + year,\n                  cluster=~State,\n                  data=reg.dat)\n```\n:::\n\n:::\n\n::::\n\n---\n\n## Common treatment timing\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\niplot(mod.twfe, \n      xlab = 'Time to treatment',\n      main = 'Event study')\n```\n\n::: {.cell-output-display}\n![](class9_files/figure-revealjs/unnamed-chunk-29-1.png){width=960}\n:::\n:::\n\n\n\n\n---\n\n## Differential treatment timing\n\n- Now let's work with the full Medicaid expansion data\n- Includes late adopters\n- Requires putting observations on \"event time\"\n\n---\n\n## Differential treatment timing\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n**Stata**\n\n::: {.cell}\n\n```{.stata .cell-code}\nssc install reghdfe\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\ndrop if expand_ever==\"NA\"\nreplace expand_year=\".\" if expand_year==\"NA\"\ndestring expand_year, replace\ngen event_time=year-expand_year\nreplace event_time=-1 if event_time==.\n\nforvalues l = 0/4 {\n\tgen L`l'event = (event_time==`l')\n}\nforvalues l = 1/2 {\n\tgen F`l'event = (event_time==-`l')\n}\ngen F3event=(event_time<=-3)\n\nreghdfe perc_unins F3event F2event L0event L1event L2event L3event L4event, absorb(state year) cluster(state)\ngen coef = .\ngen se = .\nforvalues i = 2(1)3 {\n    replace coef = _b[F`i'event] if F`i'event==1\n    replace se = _se[F`i'event] if F`i'event==1\n}\nforvalues i = 0(1)4 {\n    replace coef = _b[L`i'event] if L`i'event==1\n    replace se = _se[L`i'event] if L`i'event==1\n}\nreplace coef = 0 if F1event==1\nreplace se=0 if F1event==1\n\n* Make confidence intervals\ngen ci_top = coef+1.96*se\ngen ci_bottom = coef - 1.96*se\n\n* Limit ourselves to one observation per year\nkeep if event_time>=-3 & event_time<=4\nkeep event_time coef se ci_*\nduplicates drop\n\n* Create connected scatterplot of coefficients\n* with CIs included with rcap \n* and a line at 0 from function\nsort event_time\ntwoway (sc coef event_time, connect(line)) (rcap ci_top ci_bottom event_time) ///\n    (function y = 0, range(-3 4)), xtitle(\"Time\") ///\n    caption(\"Estimates and 95% CI from Event Study\") xlabel(-3(1)4)\n```\n:::\n\n:::\n\n\n\n::: {.column width=\"50%\"}\n**R**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(fixest)\nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat <- mcaid.data %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever,\n         time_to_treat = ifelse(expand_ever==FALSE, 0, year-expand_year),\n         time_to_treat = ifelse(time_to_treat < -3, -3, time_to_treat))\n\nmod.twfe <- feols(perc_unins~i(time_to_treat, expand_ever, ref=-1) | State + year,\n                  cluster=~State,\n                  data=reg.dat)\n```\n:::\n\n:::\n\n::::\n\n---\n\n## Differential treatment timing\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\niplot(mod.twfe, \n      xlab = 'Time to treatment',\n      main = 'Event study')\n```\n\n::: {.cell-output-display}\n![](class9_files/figure-revealjs/unnamed-chunk-32-1.png){width=960}\n:::\n:::\n\n\n\n---\n\n## Problems with TWFE\n\n- Recall goal of estimating ATE or ATT\n- TWFE and 2x2 DD identical with homogeneous effects and common treatment timing\n- Otherwise...TWFE is biased and inconsistent for ATT\n\nConsider standard TWFE specification with a single treatment coefficient, $$y_{it} = \\alpha + \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\varepsilon_{it}.$$ We can decompose $\\hat{\\delta}$ into three things:\n\n$$\\hat{\\delta}_{twfe} = \\text{VW} ATT + \\text{VW} PT - \\Delta ATT$$\n\n1. A variance-weighted ATT\n2. Violation of parallel trends\n3. Heterogeneous effects over time\n\n---\n\n## Intuition\n\n**Problems come from heterogeneous effects and staggered treatment timing**\n\n- OLS is a weighted average of all 2x2 DD groups\n- Weights are function of size of subsamples, size of treatment/control units, and timing of treatment\n- Units treated in middle of sample receive larger weights\n- **Best case:** Variance-weighted ATT\n- Prior-treated units act as controls for late-treated units, so differential timing **alone** can introduce bias \n- Heterogeneity and differential timing introduces \"contamination\" via negative weights assigned to some underlying 2x2 DDs\n\n\n---\n\n## Does it really matter?\n\n- Definitely! But how much?\n- Large treatment effects for early treated units could reverse the sign of final estimate\n- Let's explore this nice Shiny app from Kyle Butts: [Bacon-Decomposition Shiny App](https://hhsievertsen.shinyapps.io/kylebutts_did_eventstudy/).\n\n\n# Diference-in-Differences Today\n\n---\n\n## Solution\n\nOnly consider \"clean\" comparisons:\n\n- Separate event study for each treatment group vs never-treated or not-yet-treated\n- Callaway and Sant'Anna (2020)\n- Sun and Abraham (2020)\n- de Chaisemartin and D'Haultfoeuille (2020)\n- Stacking regression: Cengiz et al. (2019)\n- Imputation: Gardner (2021), and Borusyak et al. (2021)\n\n\n---\n\n## Changing mindset for estimation\n\n1. Define target parameter (e.g., ATT)...this is pretty new as a starting point\n2. Identification\n3. Estimation\n4. Aggregation\n5. Inference\n\n---\n\n## Incorporating covariates\n\n- \"Easy\" to do in regression setting, but risks of using outcomes as controls\n- Two general ways:\n    1. Outcome regression (imputation-based)\n    2. Propensity score\n\n---\n\n## Outcome regression (Heckman et al 1997)\n\n$$\\small \\hat{\\delta}^{reg} = E[Y_{t=1}|D=1] - \\left[ E[Y_{t=0}|D=1] + \\frac{1}{n^{T}} \\sum_{i \\in N_{d=1}} \\left(\\hat{\\mu}_{d=0, t=1}(X_{i}) - \\hat{\\mu}_{d=0, t=0}(X_{i})\\right) \\right],$$\n\nwhere $\\hat{\\mu}_{d,t}$ is the prediction from a regression among the untreated group using baseline covariates.\n\n- Heckman forms prediction as regression of $\\Delta Y$ on $X_{i}$ among untreated group, although could also consider separate regressions on levels\n- Conceptually...take observed value among treatment group in post-period, subtract pre-period value and the predicted trend\n\n---\n\n## IPW (Abadie, 2005)\n\n$$\\hat{\\delta}^{ipw} = E \\left[\\frac{D - \\hat{p}(D=1|X)}{1-\\hat{p}(D=1|X)} \\frac{Y_{t=1} - Y_{t=0}}{P(D=1)} \\right]$$\n\n- $Y_{t=1}$ is the observed outcome at time $t=1$, and similarly for $Y_{t=0}$\n- $\\hat{p}$ denotes the estimated propensity score from regression of $D$ on $X$ in pre-period\n- Conceptually...upweight change among treated that look a lot like the control group, downweight change among treated that look different than controls\n\n\n---\n\n## DR (Sant'Anna and Zhou)\n\n$$\\scriptsize \\hat{\\delta}^{dr} = E \\left[ \\left(\\frac{D}{P(D=1)} - \\frac{\\frac{\\hat{p}(X)(1-D)}{1-\\hat{p}(X)}}{E\\left[\\frac{\\hat{p}(X)(1-D)}{1-\\hat{p}(X)} \\right]} \\right) \\left(E[Y_{t=1}|D=1] - E[Y_{t=0}|D=1] - \\Delta \\hat{\\mu}_{0}(X)\\right) \\right]$$\n\n- Notice how this combines Heckman's outcome regression in the second part and Abadie's IPW in the first part\n\n---\n\n## The New DD\n\nI'll organize this into three types of estimators:\n\n1. Group-time comparisons (GT)\n2. Stacked\n3. Imputation\n\n---\n\n## GT1: Callaway and Sant'Anna\n\n- \"Manually\" estimate group-specific treatment effects for each period\n- Each estimate is propensity-score weighted\n- Aggregate the treatment effect estimates (by time, group, or both)\n\n---\n\n## GT1: CS Estimator (More Formally)\n\nGroup-specific treatment effects:\n\n$$ATT(g,t) = E[Y_{1,t} - Y_{0,t} | G_{g}=1],$$\nwhere $G$ denotes all feasible groups or cohorts (e.g., $g=1$ could mean states expanding in 2014, $g=2$ denotes states expanding in 2015, etc.)\n\n\n---\n\n## GT1: CS Estimator (More Formally)\n\nWith this $(g,t)$ notation, CS show:\n\n$$\\scriptsize ATT(g,t; \\tau)^{DR} = E \\left[ \\left(\\frac{G_{g}}{P(G_{g}=1)} - \\frac{\\frac{\\hat{p}_{g}(X)C}{1-\\hat{p}_{g}(X)}}{E\\left[\\frac{\\hat{p}_{g}(X)C}{1-\\hat{p}_{g}(X)} \\right]} \\right) \\left(E[Y_{t}|G_{g}=1] - E[Y_{g-\\tau-1}|G_{g}=1] - \\Delta \\hat{\\mu}_{g,t,\\tau}(X)\\right) \\right]$$\n\n- $\\tau$ denotes time from treatment, such that $Y_{g - \\tau - 1}$ denotes the outcome for some reference time period, $t=g - \\tau -1$\n- $\\Delta \\hat{\\mu}$ captures the predicted change from an outcome regression\n- $\\hat{p}_{g}$ denotes the predicted probability of being in the treatment cohort $g$\n\n\n---\n\n## GT1: CS Estimator (More Formally)\n\n- CS show a similar version of their estimator using a \"not-yet-treated\" control group rather than a never-treated.\n- Different versions include...\n    - \"regression\" based: drop the propensity score part\n    - \"IPW\": drop $\\Delta \\hat{\\mu}$\n- Only time-invariant covariates allowed\n\n---\n\n## GT1: CS Estimator (More Formally)\n\nFinally, aggregate all of the $(g,t)$ treatment effects:\n\n$$\\hat{\\delta} = \\sum_{g \\in \\mathcal{G}} \\sum_{t=2}^{\\mathcal{T}} w(g,t) \\times ATT(g,t)$$\n\n---\n\n## GT1: CS Estimator (in Practice)\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n**Stata**\n\n::: {.cell}\n\n```{.stata .cell-code}\nssc install csdid\nssc install event_plot\nssc install drdid\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\negen stategroup=group(state)\ndrop if expand_ever==\"NA\"\nreplace expand_year=\"0\" if expand_year==\"NA\"\ndestring expand_year, replace\n\ncsdid perc_unins, ivar(stategroup) time(year) gvar(expand_year) notyet\nestat event, estore(cs)\nevent_plot cs, default_look graph_opt(xtitle(\"Periods since the event\") ytitle(\"Average causal effect\") xlabel(-6(1)4) title(\"Callaway and Sant'Anna (2020)\")) stub_lag(T+#) stub_lead(T-#) together\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**R**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(did)\nlibrary(DRDID)\nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat <- mcaid.data %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever,\n         expand_year=ifelse(is.na(expand_year),0,expand_year)) %>%\n  filter(!is.na(perc_unins)) %>%\n  group_by(State) %>%\n  mutate(stategroup=cur_group_id()) %>% ungroup()\n\nmod.cs <- att_gt(yname=\"perc_unins\", tname=\"year\", idname=\"stategroup\",\n                 gname=\"expand_year\",\n                 data=reg.dat, panel=TRUE, est_method=\"dr\",\n                 allow_unbalanced_panel=TRUE)\nmod.cs.event <- aggte(mod.cs, type=\"dynamic\")\n```\n:::\n\n:::\n\n::::\n\n---\n\n## CS in Practice\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nggdid(mod.cs.event,\n      legend=FALSE)\n```\n\n::: {.cell-output-display}\n![](class9_files/figure-revealjs/unnamed-chunk-35-1.png){width=960}\n:::\n:::\n\n\n\n---\n\n## GT2: Sun and Abraham\n\n- Standard event study problems:\n    - coefficient estimates are potentially biased due to treatment/control group construction\n    - i.e., \"contamination\" of individual $\\delta_{\\tau}$ from other leads/lags\n- Solution: Estimate fully interacted model\n\n::: {.fragment}\n$$y_{it} = \\gamma_{i} + \\gamma_{t} + \\sum_{g} \\sum_{\\tau \\neq -1} \\delta_{g \\tau} \\times \\text{1}(i \\in C_{g}) \\times D_{it}^{\\tau} + \\beta x_{it} + \\epsilon_{it}$$\n:::\n\n---\n\n## GT2: Sun and Abraham\n\n$$y_{it} = \\gamma_{i} + \\gamma_{t} + \\sum_{g} \\sum_{\\tau \\neq -1} \\delta_{g \\tau} \\times \\text{1}(i \\in C_{g}) \\times D_{it}^{\\tau} + \\beta x_{it} + \\epsilon_{it}$$\n\n::: {.fragment}\n- $g$ denotes a group and $C_{g}$ the set of individuals in group $g$\n- $\\tau$ denotes time periods\n- $D_{it}^{\\tau}$ denotes a relative time indicator\n:::\n\n---\n\n## GT2: Sun and Abraham\n\n$$y_{it} = \\gamma_{i} + \\gamma_{t} + \\sum_{g} \\sum_{\\tau \\neq -1} \\delta_{g \\tau} \\times \\text{1}(i \\in C_{g}) \\times D_{it}^{\\tau} + \\beta x_{it} + \\epsilon_{it}$$\n\n::: {.fragment}\n- Intuition: Standard regression with different event study specifications for each treatment group\n- Aggregate $\\delta_{g\\tau}$ for standard event study coefficients and overall ATT\n:::\n\n\n---\n\n## GT2: Sun and Abraham in Practice\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n**Stata**\n\n\n::: {.cell}\n\n```{.stata .cell-code}\nssc install eventstudyinteract\nssc install avar\nssc install event_plot\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\ndrop if expand_ever==\"NA\"\negen stategroup=group(state)\nreplace expand_year=\".\" if expand_year==\"NA\"\ndestring expand_year, replace\ngen event_time=year-expand_year\ngen nevertreated=(event_time==.)\n\nforvalues l = 0/4 {\n\tgen L`l'event = (event_time==`l')\n}\nforvalues l = 1/2 {\n\tgen F`l'event = (event_time==-`l')\n}\ngen F3event=(event_time<=-3)\neventstudyinteract perc_unins F3event F2event L0event L1event L2event L3event L4event, vce(cluster stategroup) absorb(stategroup year) cohort(expand_year) control_cohort(nevertreated)\n\nevent_plot e(b_iw)#e(V_iw), default_look graph_opt(xtitle(\"Periods since the event\") ytitle(\"Average causal effect\") xlabel(-3(1)4)\ttitle(\"Sun and Abraham (2020)\")) stub_lag(L#event) stub_lead(F#event) plottype(scatter) ciplottype(rcap) together\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n**R**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(fixest)\nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat <- mcaid.data %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever,\n         expand_year = ifelse(expand_ever==FALSE, 10000, expand_year),\n         time_to_treat = ifelse(expand_ever==FALSE, -1, year-expand_year),\n         time_to_treat = ifelse(time_to_treat < -4, -4, time_to_treat))\n\nmod.sa <- feols(perc_unins~sunab(expand_year, time_to_treat) | State + year,\n                  cluster=~State,\n                  data=reg.dat)\n```\n:::\n\n:::\n\n::::\n\n---\n\n## Sun and Abraham in Practice\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\niplot(mod.sa,\n      xlab = 'Time to treatment',\n      main = 'SA Event study')\n```\n\n::: {.cell-output-display}\n![](class9_files/figure-revealjs/unnamed-chunk-38-1.png){width=960}\n:::\n:::\n\n\n---\n\n## GT3: de Chaisemartin and D'Haultfoeuille (CH)\n\n- More general than other approaches\n- Considers \"fuzzy\" treatment (i.e., non-discrete treatment)\n- Considers fixed effects and first-differencing\n- Allows treatment to turn on and off (not allowed in CS or SA)\n\n::: {.fragment}\nNew paper from Callaway, Goodman-Bacon, and Sant'Anna also looks at DD with continuous treatment\n:::\n\n---\n\n## GT3: CH Approach\n\n- Essentially a series of 2x2 comparisons\n- Aggregates up to overall effects\n\n\n---\n\n## CH in Practice\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n**Stata**\n\n\n::: {.cell}\n\n```{.stata .cell-code}\nssc install did_multiplegt\nssc install event_plot\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\ndrop if expand_ever==\"NA\"\negen stategroup=group(state)\nreplace expand_year=\".\" if expand_year==\"NA\"\ndestring expand_year, replace\ngen event_time=year-expand_year\ngen nevertreated=(event_time==.)\ngen treat=(event_time>=0 & event_time!=.)\n\ndid_multiplegt perc_unins stategroup year treat, robust_dynamic dynamic(4) placebo(3) breps(100) cluster(stategroup) \nevent_plot e(estimates)#e(variances), default_look graph_opt(xtitle(\"Periods since the event\") ytitle(\"Average causal effect\") ///\ntitle(\"de Chaisemartin and D'Haultfoeuille (2020)\") xlabel(-3(1)4)) stub_lag(Effect_#) stub_lead(Placebo_#) together\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n**R**(not the same as in **Stata**)\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DIDmultiplegt)\nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat <- mcaid.data %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         treat=case_when(\n           expand_ever==FALSE ~ 0,\n           expand_ever==TRUE & expand_year<year ~ 0,\n           expand_ever==TRUE & expand_year>=year ~ 1))\n\nmod.ch <- did_multiplegt(df=reg.dat, Y=\"perc_unins\", G=\"State\", T=\"year\", D=\"treat\",\n                         placebo=4, dynamic=5, brep=50, cluster='State', covariance=TRUE, \n                         average_effect=\"simple\")\n```\n\n::: {.cell-output-display}\n![](class9_files/figure-revealjs/unnamed-chunk-40-1.png){width=960}\n:::\n:::\n\n:::\n\n::::\n\n---\n\n## CH in Practice\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nlibrary(broom)\n# Create a tidier for \"multiplegt\" objects\ntidy.did_multiplegt = function(x, level = 0.95) {\n  ests = x[grepl(\"^placebo_|^effect|^dynamic_\", names(x))]\n  ret = data.frame(\n    term      = names(ests),\n    estimate  = as.numeric(ests),\n    std.error = as.numeric(x[grepl(\"^se_placebo|^se_effect|^se_dynamic\", names(x))]),\n    N         = as.numeric(x[grepl(\"^N_placebo|^N_effect|^N_dynamic\", names(x))])\n    ) |>\n    # For CIs we'll assume standard normal distribution\n    within({\n      conf.low  = estimate - std.error*(qnorm(1-(1-level)/2))\n      conf.high = estimate + std.error*(qnorm(1-(1-level)/2))\n      })\n  return(ret)\n}\n\ntidy.mod.ch <- tidy.did_multiplegt(mod.ch)\n\nlibrary(ggplot2)\ntheme_set(theme_minimal(base_family = \"ArialNarrow\")) # Optional\ntidy.mod.ch |>\n  within({\n    term = gsub(\"^placebo_\", \"-\", term)\n    term = gsub(\"^effect\", \"0\", term)\n    term = gsub(\"^dynamic_\", \"\", term)\n    term = as.integer(term)\n    }) |>\n  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +\n  geom_pointrange() +\n  labs(\n    x = \"Time to treatment\", y = \"Effect size\", title = \"CH Event-study plot\"\n    )\n```\n\n::: {.cell-output-display}\n![](class9_files/figure-revealjs/unnamed-chunk-41-1.png){width=960}\n:::\n:::\n\n\n---\n\n## CH in practice\n\nSome barriers to this estimator in practice (at least, as implemented in `R` right now)\n\n- Relatively slow\n- Not user friendly\n- Odd results\n\n\n---\n\n## Cengiz et al. (2019): Stacked regression\n\n- \"Stacked\" event studies\n- Estimate event study for every treatment group, using never-treated as controls\n- Aggregate to overall average effects\n\n---\n\n## Cengiz et al. (2019)\n\n1. Define event window, $t\\in [\\kappa_{a}, \\kappa_{b}]$ (e.g., 3 pre-periods and 5 post-periods, $\\kappa_{a}=3$ and $\\kappa_{b}=5$)\n2. Split the data into $g=1,...,G$ different \"groups\", as defined by treatment cohort, each with adoption date denoted by $\\omega_{g}$\n    - observations outside of the $[\\omega_{g} - \\kappa_{a}, \\omega_{g} + \\kappa_{b}]$ interval are dropped\n3. Append (i.e., stack) each $g$th dataset\n4. Run stacked event study allowing for different set of event study coefficients and fixed effects for every group $g$\n\n$$y_{itg} = \\sum_{\\tau=-\\kappa_{a}}^{\\kappa_{b}} \\delta_{\\tau} \\times D_{ig} \\times 1(t-\\omega_{g} = \\tau) + \\gamma_{ig} + \\gamma_{\\tau g} + \\varepsilon_{itg}$$\n\n---\n\n## Cengiz et al. (2019)\n\n- Intuitively: run event study on every cohort, $g$\n- Control units (never treated or very late treated) will be duplicated over cohorts\n- Need to cluster at the unit or unit/cohort level (probably unit level otherwise not accounting for duplication)\n- **Alternative:** Among controls included in multiple cohorts, randomly assign them to one cohort\n\n---\n\n## Quick comparison\n\n- Allows time-varying covariates\n- Inference is less clear\n- Likely estimating some variance-weighted ATT...not clear what those weights are anymore\n- Seemingly stronger parallel trends assumptions for each cohort\n\n---\n\n## Imputation estimators\n\n1. Estimate group and time fixed effects via first stage regression only among non-treated units\n2. Predict outcome for all observations and residualize\n3. Run standard event study specification on residualized outcome variable\n\nNote: Estimate with GMM to account for first-stage prediction\n\n---\n\n## Gardner (2021)\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n**Stata**\n\n`did2s`\n:::\n\n::: {.column width=\"50%\"}\n\n**R**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(did2s)\nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat <- mcaid.data %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever,\n         expand_year = ifelse(expand_ever==FALSE, 10000, expand_year),\n         time_to_treat = ifelse(expand_ever==FALSE, -1, year-expand_year),\n         time_to_treat = ifelse(time_to_treat < -3, -3, time_to_treat))\n\nmod.2s <- did2s(reg.dat, yname=\"perc_unins\", \n                treatment=\"treat\", \n                first_stage = ~ 0 | State + year,\n                second_stage = ~i(time_to_treat, ref=-1),\n                cluster_var=\"State\")\n```\n:::\n\n:::\n\n::::\n\n---\n\n## Gardner (2021) in Practice\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\niplot(mod.2s, main=\"2SDID Event Study\", xlab=\"Event time\")\n```\n\n::: {.cell-output-display}\n![](class9_files/figure-revealjs/unnamed-chunk-43-1.png){width=960}\n:::\n:::\n\n\n---\n\n## Borusyak et al. (2021)\n\n- Estimate regression only for untreated observations\n- Predicted untreated outcome among the treated observations and take the difference\n- Aggregate differences to form overall weighted average effect\n\n\n---\n\n## Borusyak et al. in practice\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n**Stata**\n\n`did_imputation`\n\n:::\n\n::: {.column width=\"50%\"}\n\n**R**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(didimputation)\nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat <- mcaid.data %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever,\n         expand_year = ifelse(expand_ever==FALSE, 0, expand_year))\n\nmod.bea <- did_imputation(reg.dat, yname=\"perc_unins\", \n                gname=\"expand_year\",\n                tname=\"year\",\n                idname=\"State\",\n                first_stage = ~ 0 | State + year,\n                cluster_var=\"State\",\n                horizon=TRUE,\n                pretrends=-3:-1)\n```\n:::\n\n:::\n\n::::\n\n\n---\n\n## Borusyak et al. in practice\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\ncoef.bea <- mod.bea %>%\n    select(rel_year = term, estimate, std.error) %>%\n    mutate(\n        ci_lower = estimate - 1.96 * std.error,\n        ci_upper = estimate + 1.96 * std.error,\n        group = \"Borusyak et al Imputation\",\n        rel_year = as.numeric(rel_year)\n    )\n\nggplot(coef.bea) +\n    geom_hline(yintercept = 0, linetype = \"dashed\") +\n    geom_vline(xintercept = -0.5, linetype = \"dashed\") +\n    geom_linerange(mapping = aes(x = rel_year, ymin = ci_lower, ymax = ci_upper), color = \"grey30\") +\n    geom_point(mapping = aes(x = rel_year, y = estimate, color = group), size = 2) +\n    scale_x_continuous(breaks = -3:5, minor_breaks = NULL) +\n    scale_y_continuous(minor_breaks = NULL) +\n    labs(x = \"Relative Time\", y = \"Estimate\", color = NULL, title = NULL) +\n  theme_bw() + theme(legend.position=\"none\")\n```\n\n::: {.cell-output-display}\n![](class9_files/figure-revealjs/unnamed-chunk-45-1.png){width=960}\n:::\n:::\n\n\n# Discussion\n\n---\n\n## Seems like lots of \"solutions\"\n\n- Callaway and Sant'Anna (2020)\n- Sun and Abraham (2020)\n- de Chaisemartin and D'Haultfoeuille (2020)\n- Cengiz et al (2019)\n- Gardner (2021) and Borusyak et al. (2021)\n\n::: {.fragment}\nGoodman-Bacon (2021) explores the problems but doesn't really propose a solution (still very important work though!)\n:::\n\n---\n\n## Comparison\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R Code\"}\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(fixest)\nmcaid.data <- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat <- mcaid.data %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever,\n         time_to_treat = ifelse(expand_ever==FALSE, 0, year-expand_year),\n         time_to_treat = ifelse(time_to_treat < -3, -3, time_to_treat))\n\nmod.twfe <- feols(perc_unins~i(time_to_treat, expand_ever, ref=-1) | State + year,\n                  cluster=~State,\n                  data=reg.dat)\n\n\ncoef.twfe <- tidy(mod.twfe) %>%\n  mutate(term=str_replace(term,\"time_to_treat::\",\"\"),\n         term=str_replace(term,\":expand_ever\",\"\")) %>%\n  rename(rel_year=term) %>%\n  select(rel_year, estimate, std.error) %>%\n  bind_rows(tibble(rel_year=\"-1\", estimate=0, std.error=0)) %>%  \n  mutate(\n    ci_lower = estimate - 1.96 * std.error,\n    ci_upper = estimate + 1.96 * std.error,\n    group = \"TWFE\",\n    rel_year = as.numeric(rel_year)\n  ) %>%\n  filter(rel_year>=-3, rel_year<=5)\n\ncoef.2s <- tidy(mod.2s) %>%\n  mutate(term=str_replace(term,\"time_to_treat::\",\"\")) %>%\n  rename(rel_year=term) %>%\n  select(rel_year, estimate, std.error) %>%\n  bind_rows(tibble(rel_year=\"-1\", estimate=0, std.error=0)) %>%  \n  mutate(\n    ci_lower = estimate - 1.96 * std.error,\n    ci_upper = estimate + 1.96 * std.error,\n    group = \"Gardner 2SDiD\",\n    rel_year = as.numeric(rel_year)\n  )\n\ncoef.sa <- tidy(mod.sa) %>%\n  mutate(term=str_replace(term,\"time_to_treat::\",\"\")) %>%\n  rename(rel_year=term) %>%\n  select(rel_year, estimate, std.error) %>%\n  bind_rows(tibble(rel_year=\"-1\", estimate=0, std.error=0)) %>%    \n  mutate(\n    ci_lower = estimate - 1.96 * std.error,\n    ci_upper = estimate + 1.96 * std.error,\n    group = \"Sun and Abraham\",\n    rel_year = as.numeric(rel_year)\n  ) %>%\n  filter(rel_year>=-3, rel_year<=5)\n\n\ncoef.cs <- tidy(mod.cs.event) %>%\n  select(rel_year=event.time, estimate, ci_lower=conf.low, ci_upper=conf.high) %>%\n  mutate(rel_year=as.numeric(rel_year),\n         group = \"Callaway and Sant'Anna\") %>%\n  filter(rel_year>=-3, rel_year<=5)\ncoef.cs <- as_tibble(coef.cs)\n\ncoef.all <- bind_rows(coef.twfe, coef.cs, coef.sa, coef.2s, coef.bea) %>%\n  select(rel_year, estimate, ci_lower, ci_upper, group)\n\nggplot(coef.all, aes(x=rel_year, y=estimate)) + \n  geom_point(aes(color=group), size = 2, position=position_dodge(width=0.7))  +\n  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position=position_dodge2(width=0.7)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = -0.5, linetype = \"dashed\") +\n  theme(legend.position=\"bottom\") +\n  guides(color=guide_legend(ncol=2, title=NULL)) +\n  scale_x_continuous(breaks = -3:5, minor_breaks = NULL) +\n  scale_y_continuous(minor_breaks = NULL) +\n  labs(x = \"Relative Time\", y = \"Estimate\", color = NULL, title = NULL)\n```\n\n::: {.cell-output-display}\n![](class9_files/figure-revealjs/unnamed-chunk-46-1.png){width=960}\n:::\n:::\n\n\n\n---\n\n## Comparison\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n**Similarities**\n\n- Focus on clean treatment/control\n- Focus on event study framework (not a single overall effect)\n- Impose some form of parallel trends assumption\n:::\n\n::: {.column width=\"50%\"}\n\n**Differences**\n\n- Is there a \"never treated\" group?\n- Can treatment turn on and off?\n- How to include covariates?\n- How to do inference?\n:::\n\n::::\n\n\n---\n\n## General advice\n\n1. Do you have staggered treatment adoption? If so, will need to consider something beyond TWFE event study (even if it doesn't change results)\n2. Do you need time-varying covariates? If so, consider Sun and Abraham or stacked regression (2SDD and imputation can only use pre-treatment covariates). But also, why do you need time-varying covariates?\n3. Is treatment \"strict\"? If not, CH is only option right now\n4. Does treatment turn on and off again? If so, CH or perhaps focus on \"clean\" treatment adoptions\n5. Inference? Stacked regression is harder here. (see @wing2024wp for recent work on this)\n\n\n---\n\n## Other topics\n\n- Can you test for parallel pre-trends?\n- Recent work says such tests are underpowered\n- Consider potential violations of parallel trends and assess results\n    - Intuitively \"easy\" to do in manual $(g,t)$ or imputation setting, harder in pure regression setting\n    - See @rambachan2023 and @freyaldenhoven2021wp for recent work on this\n    - Parallel trends sensitive to functional form, see @roth2023emta\n\n\n# Some points on the DD empirical exercise\n\n---\n\n## 1. The Data\n\n1. HCRIS\n2. POS\n3. KFF Medicaid Expansion\n\n\n---\n\n## HCRIS\n\n- Comprehensive dataset on hospital financials and other details\n- Challenging to get information out of these reports\n- Very messy with lots of misreporting\n- Hospitals identified by \"Medicare Provider Number\" (also known as CMS Certification Number, or CCN) and \"NPI\"\n- We'll work with the provider number in this assignment\n\n---\n\n## POS\n\n- \"Cumulative\" file listing all Medicare-approved facilities other than clinical labs (those are in separate files)\n- Duplicate observations in each year\n- Closed hospitals **should** stay in the data every year, with a termination date filled when closed\n- **LOTS** more facilities than hospitals\n\n---\n\n## KFF Medicaid Expansion\n\n- List of states and dates in which Medicaid was implemented\n\n---\n\n## 2. The analysis\n\n1. Summary statistics and figures\n2. DD, TWFE, Event Studies\n3. Sun and Abraham\n4. Callaway and Sant'Anna\n5. Callaway and Sant'Anna with \"Honest\" pre-trends\n\n\n---\n\n## 3. Discussion and reflection\n\n- Discussion: Looking for overall takeaways here, nothing too formal. \n- Reflection: Explain something you found surprising. Maybe it was something that you enjoyed learning or implementing. Maybe it was something that you struggled with but that you thought, ex ante, would be easier. Or maybe you were surprised at how awesome you are! Anything goes really...just be genuine.\n\n---\n\n## 4. Expectations\n\n- PDF should be more like a report than a research notebook (code goes in the repo, not in the report)\n- Separate your analysis from your writing (perhaps by cleaning and then saving your workspace, and importing it into your markdown doc)\n- Tables and Figures should be near-publication quality, with clean and clear variable names, axes, labels, etc.\n- Spend time on good workflow and professional looking products...you can re-use all of this code and workflow for the rest of your career!\n\n\n\n\n\n## References\n\n",
    "supporting": [
      "class9_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ],
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}